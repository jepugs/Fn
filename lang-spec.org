#+title: Fn Language Specification
#+author: Jack Pugmire

* About this Document

This document is a minimal formal spec of fn for Version 0.1.0. The goal is to completely describe
fn without any ambiguity so that it may be implemented precisely, with no undefined behavior. It is
meant mainly as an aid to the implementor.


* Lexical Analysis

The component which processes Fn source into lexical tokens is called the
*scanner*. Conceptually, we put in a sequence of bytes and get back a sequence
of tokens.

Tokens are dividide into two groups: fixed width and variable width. The fixed
width tokens are:
- '(' :: left paren
- ')' :: right paren
- '[' :: left bracket
- ']' :: right bracket
- '{' :: left brace
- '}' :: right brace
- '\'' :: quote
- '`' :: backtick
- ',@' :: comma at
- ',' :: comma
- '$`' :: dollar backtick
- '$(' :: dollar paren
- '$[' :: dollar bracket
- '${' :: dollar brace

Fixed width tokens are generated when the scanner encounters one of the
corresponding quoted strings above.

Variable width tokens are:
- <number> :: numeric literal
- <string> :: string literal
- <symbol> :: symbol
- <dot> :: dot expression (2 or more symbols separated by '.')

** Comments

A comments begins with the unescaped character ~';'~ and end at the end of the
line.

Comments are skipped over without generating a token.

** Numbers, Symbols, and Dots

Numbers are defined according to regular expressions as in the following
pseudo-BNF grammar:

#+begin_src
<number> ::= "[+-]?(<dec>|<hex>)"
<dec>    ::= "[0-9]+\.?<exp>?"
           | "[0-9]*\.[0-9]+<exp>?"
<exp>    ::= "[eE][+-]?[0-9]+"
<hex>    ::= "0[Xx][0-9A-Fa-f]+\.?"
           | "0[Xx][0-9A-Fa-f]*\.[0-9A-Fa-f]"
#+end_src

A symbol is defined to be a sequence of symbol characters and escaped characters
which is not a number. Symbol characters are all printable ASCII characters
other than whitespace or those contained in the string ~";(){}[]\"\\'`,."~. An
escaped character is a sequence of two characters, the escape ~'\\'~ followed by
an arbitrary character. When the symbol is internalized, the escape character is
ignored, so its name will contain only the second character of the escape
sequence.

If an escape character is followed by EOF, a scanning error is raised.

Note that by injecting an escape character, one may cause numbers to be treated
as symbols. Adding an escape in front of any normal character normally no
effect, but in this case, it causes the number reader to fail, so the number's
characters will read as a symbol.

Finally, a dot token is a symbol token which contains the dot character ~'.'~,
subject to some additional restrictions. Dots can not occur in the first or last
position of the string, and it can not contain successive dots. In addition, the
substring before the first dot may not be a syntactically valid number. If any
of these conditions is violated, a scanning error is raised.

** TODO String Literals

String scanning starts when the scanner encounters the (unescaped) character
~'"'~ and ends when it encounters an unescaped ~'"'~. Along the way, all bytes
encountered are read verbatim, except for the escape character '\\', which is
followed by an escape sequence. The entire escape sequence is read into the
string according to the following table [fn:c-string-escapes]:
- '\'' :: single quote
- '\"' :: double quote
- '\?' :: question mark
- '\a' :: ASCII bell
- '\b' :: backspace
- '\f' :: form feed
- '\n' :: newline
- '\r' :: ASCII carriage return
- '\t' :: tab
- '\v' :: vertical tab
- '\NNN' (NNN is a 1- to 3- digit octal number) :: byte NNN (octal)
- '\xNN' (NN any two-digit hex number) :: the byte NN (hexadecimal)
- '\uC' (C any 4-digit hex unicode code point) :: unicode code point (2 bytes)
- '\UC' (C any 8-digit hex unicode code point) :: unicode code point (4 bytes)

[fn:c-string-escapes] These string escapes are mainly the same as the ones in C.

** Source Encoding

Currently, Fn only supports ASCII encoded text files. Behavior on other/extended
encodings is undefined. In the future, Fn will be extended so that UTF-8
characters can appear in strings and symbols.


* TODO Parsing and Quoting

The *parser* is the next piece of the pipeline after the scanner. The parser
converts streams of tokens into abstract syntax tree objects.

Fn has a remarkably simple structure once parsed. The produced objects are trees
whose leaves are either symbols, string literals, or numeric literals. These
leaf forms are collectively referred to as *atoms*, and correspond to symbol,
string, or number (resp) values in Fn. This correspondence is important to Fn's
metaprogramming facility, macros.


* Data Model

Every value in Fn is an *object*. All objects have a single *type*, which
describes the contents of the object as well as the supported operations. The
types of objects are:

- number :: floating point number (62 bits)
- string :: sequence of bytes. Max length 2^32-1
- symbol :: internalized string
- bool :: special constants true and false
- null :: null value
- list :: immutable singley-linked list
- table :: (mutable) generalized key-value store. Keys may be any object
- namespace :: key-value store associating symbols to values. Represents a
  global environment.
- function :: a function object which may be called

Lists and tables are the primary means for structuring data in Fn. Tables in
particular can have an ~__on-call__~ entry defined, which allows the table to be
called like a function (see [[Calling Tables as Functions]]). It is intended to use
this facility for message passing OOP.

Fn is meant for mostly functional programming, and tables are the only mutable
native data structure. (In the future, a mutable sequence of bytes type may be
added for working with foreign code). In general, stateful programming should be
avoided.

Whenever a new data structure must be defined, there are a number of operations
which will naturally be associated to it. Making these methods (rather than
global functions) allows the object itself to be treated as a makeshift
namespace to access the functions that act on it, which shortens code and allows
common names to be reused. It also provides a straightforward way to accomplish
polymorphism, by having multiple table-based data structures implement the same
methods.

We suggest creating class data structures to describe the methods supported by a
data structure. Examples of this will be provided with the Fn source code.


* Variable and Namespaces

For our purposes, a *variable* is a place to hold a value which is named by an
identifier. Variables are defined through dedicated language facilities, and
their values may be recalled using their names.

** Global Variables

Global variables may be defined or accessed at any point in the program source.
A runtime error occurs if an attempt is made to access a global variable before
its definition.

Global variables are created using the ~def~ special operator. Attempting to
define a global variable when it already exists will cause an error. In
addition, global variables are immutable. Attempts to change them with ~set!~
will result in an error. Global variables which are tables may still have their
contents set, however this is generally discouraged except for the purposes of
performing a one-time initialization of the table.

Global variables are stored in namespaces. Namespaces exist in a global
hierarchy which is accessible at runtime using the special global variable ~ns~.
See [[Namespace Loading]] for details. Note that once loaded, namespaces are
immutable objects, in order to preserve immutability of global variables.

At any given expression in an Fn program, there is understood to be a single
active global namespace. References to global variables made in the expression
are resolved in this namespace.

** Local Variables and Shadowing

Local variables in Fn are managed using the lexical scope semantics typical of
modern programming languages. Local variables may be introduced using the
special operators ~with~ or ~let~. We say a local variable is "in scope" if it is
accessible from a given lexical context in source code (so global variables are
always in scope).

If there are multiple local variables in scope with the same name, then the
variable introduced at the deepest level takes precedent, (rendering those
higher up in scope temporarily inaccessible).

** Import and Namespace Loading

Namespaces are uniquely identified by dot forms. The first time a namespace is
imported, it must be *loaded* from a file. Subsequent imports will not trigger
reloading.

Namespaces are identified by dot expressions. The dot expression is converted to
a path by turning dots into a path separators and attaching the filename
extension ".fn" to the last element in the list. E.g. "my.lib.component" would
translate to "my/lib/component.fn".

Import searches for this namespace file in each directory in the namespace
search path.

Once a namespace is loaded, it is added to object ~ns~. ~ns~ is a namespace
object containing all loaded namespaces. The namespaces are contained in a
hierarchy within ns, so that the dot expression identifying the namespace can be
used to access it within ~ns~. E.g. ~my.lib.component~ would be
~ns.my.lib.component~. ~ns~ is automatically bound as a variable whenever a new
namespace is created.

In addition, every namespace automatically inherits every variable from
~fn.core~.

** Namespace Search Path

Note: this depends on a UNIX-like enivornment and directory structure. Support
for Windows will require some additional work.

The last path in the search path is always ~${PREFIX}/lib/Fn/ns~, the system
namespace directory. Here ~${PREFIX}~ is a location determined at compile time,
probably ~/usr~ or ~/usr/local~. By default, the interpreter working directory
is searched first, then ~${HOME}/.local/lib/Fn/ns~, however this can be
controlled using the ~--no-wd~ and ~--no-home~ interpreter flags to suppress
these locations respectively.

When evaluating a file, the interpreter changes its working directory to the
directory containing that file. The repl working directory is the one from which
the program was launched.

It is recommended that single file scripts use the flag ~--no-wd~ and that
system scripts use ~--sys-only~, which is equivalent to using both ~--no-wd~ and
~--no-home~.

** [Future Addition] Dynamically-scoped variables

Dynamic global variables will be added as a feature in a future release of Fn.
These will function very similar to dynamic variables in Common Lisp. The
general design is this:

- Add a special operator called ~def*~ which behaves like ~def~ but defines
  global dynamic variables
- Dynamic variables must have earmuffs around their names. This will be enforced
  by the compiler.
- Dynamic variables may be locally rebound using ~let~ or ~with~.

The main difference between dynamic variables and lexical variables is that when
a function is called, the dynamic variable bindings are forwarded to the callee.
Lexical variables, on the other hand, get "reset" on every function call. This
relationship is perhaps best conceptualized by considering the relationship
between a program's call graph and its AST. When a lexical variable is
introduced in a vertex of the AST, this variable is available precisely to the
vertex's children in the AST. On the other hand, when a dynamic variable is
introduced somewhere in the call graph, it is accessible to all the children in
the call graph.

A program's call graph is generally much more complicated than its AST, (the
call graph is not usually a tree), so misuse of dynamic variables can cause
terrible readability problems.

In practice, dynamic variables are mainly useful for cases where you may want to
provide additional information to a function without extending its parameter
list. Since dynamic variables do not need to be passed explicitly, they are also
useful for situations where we have many independent functions which need the
same information.

A concrete example of why we would want dynamic variables is for plotting
libraries (such as ggplot2 or matplotlib). These libraries are generally very
imperative and involve building a plot one step at a time. At each step, there
are a number of formatting options to pass around, as well as some sort of
global plot object which is mutated. By using dynamic variables, we can avoid
creating a global object and keep formatting options out of the argument list.

#+BEGIN_SRC
;; example: hypothetical plotting library. We use dynamic variables to set up
;; the plotting environment and then plot some data.

(import plot-lib as pl)

(with (pl.*current-plot* (pl.new-plot "title")
       pl.*line-style* 'dashed
       pl.*color-scheme* pl.colors.bright)
  (pl.label-axis x)
  (pl.plot-data my-data))
#+END_SRC


* Expressions

#+begin_src
program ::= expr* expr ::= immediate
        | variable
        | special-form
        | function-call
        | macro-call
#+end_src

** Immediate Expressions and Variables
Syntax:
#+begin_src
immediate ::= boolean 
          | null
          | number
          | string
variable ::= non-special-symbol
#+end_src

An immediate expression is a literal representing a constant value. On
evaluation, immediate expressions immediately return the value they represent.
See [[Syntax]] for information on how immediate expression syntax.

Variables are represented by non-special symbols, (where special symbols are
those naming special forms, boolean values, or null). If there exists a binding
in the current environment for the provided symbol, then its value is returned.
Otherwise an exception is raised.


** Special forms
Special forms are so called because they have different semantics than function
or macro calls.

*** and
Syntax:
#+begin_src
and-expr ::= "(" "and" expr* ")"
#+end_src

Expressions are evaluated one at a time until a logically false value is
encountered, then returns ~false~. If the end of the list is reached, returns
~true~.

*** cond
Syntax:
#+begin_src
cond-expr ::= "(" "cond" cond-case+ ")"
cond-case ::= expr expr
#+end_src

For each cond-case, the following is done:
- evaluate the first expression
- if the first expression is logically true, return the value of the second
  expression
- otherwise, proceed to the next cond-case.

If the end of the list is reached, returns ~null~.
*** def
Syntax:
#+begin_src
def-expr ::= "(" "def" identifier expr ")"
         | "(" "def" func-proto expr+")"
func-proto ::= "(" identifier param-list ")"
#+end_src

Create a (global) binding in the current namespace. The first syntax binds the
identifier to the value of the expression. The second syntax creates a function
with the specified name and parameter list and the expressions as its body. In
either case, if the identifier is already bound, an exception is raised.

Returns ~null~.

*** TODO defmacro
Syntax:
#+begin_src
defmacro-expr ::= "(" "defmacro" macro-proto expr+ ")"
macro-proto ::= "(" identifier param-list ")"
#+end_src

*** defn
*** do
Syntax:
#+begin_src
do-expr ::= "(" "do" expr* ")"
#+end_src

Evaluates provided expressions one at a time, returning the value of the last
one, or ~null~ if no expressions are given.

*** dot
Syntax:
#+begin_src
dot-expr ::= symbol "." dot-key
           | "(" "dot" symbol+ ")"
dot-key  ::= symbol | symbol "." dot-key
#+end_src

In addition, when using the inline "." notation, there may not be space between
the dot and the symbols.

The first symbol (leftmost in the inline notation) must name a variable bound to
either a namespace or a table. The next symbol is used as a key to access an
element of the table. If additional symbols are provided, then they are used as
keys to recursively descend into a tree of tables. An exception is raised if one
of the keys is invalid or if an attempt is made to access an object which is
neither a table nor a namespaec.

~dot~ is generally used in the form of dot syntax as a concise way to handle
both namespaces and tables whose keys are symbols.

*** dollar-fn
Syntax:
#+begin_src
dollar-fn-expr ::= "(" "dollar-fn" expr ")"
               | "$(" expr+ ")"
               | "$[" expr+ "]"
               | "${" expr+ "}"
               | "$`" form
#+end_src

Creates an anonymous function which evaluates the provided expression. With the
"$" syntax, this is the expression after the dollar sign. (The only expressions
which may follow are parenthesized forms, quasiquote forms, or list/table
expressions).

Within the provided expression, variables named ~$N~ where N is a nonnegative
integer, are bound to the corresponding positional parameters starting from 0.
In addition, ~$~ is bound to the first parameter ~$0~ and ~$&~ is used for a
variadic parameter.

The parameter list for the created function accepts as many positional
parameters as the highest value of N and a variadic parameter only if ~$&~
appears in the expression. (This is accomplished by performing code-walking,
including macroexpansion, before compiling the ~dollar-fn~).

*** if
Syntax:
#+begin_src
if-expr ::= "(" "if" test-expr expr expr ")"
test-expr ::= expr
#+end_src

Evaluates test-expr. If the result is logically true, returns the value of the
second argument, otherwise returns the value of the final argument.

*** import
Syntax:
#+begin_src
import-expr ::= "(" "import" import-designator [identifier]
                    [import-designator] ")"
import-designator ::= dot-expr | string | symbol
#+end_src

Load a namespace and bind it to a global variable. If an identifier is provided,
then that name is used. Otherwise, the variable name is chosen based upon the
kind of import-designator provided:
- if it is a dot form, then the last key in the dot form is used (e.g. ~pkg.lib~
  would give a variable name ~lib~).
- if it is a symbol, the symbol itself is used
- if it is a string, then the stem of the filename is converted to a symbol and
  then used

In addition, if the special identifier ~_~ is used, then no variable is created
(but namespace loading will still occur).

Specifying a second import designator allows the position in ns object to be
controlled.

See [[Namespace Loading]] for information about how files are located.

*** fn
Syntax:
#+begin_src
fn-expr ::= "(" "fn" "(" param-list ")" expr+ ")"
#+end_src

Returns a function object with the provided parameter list and function body. If
the enclosing environment does not already have an associated closure, one is
created. The resulting function's closure ID will be the same as the current
environment.

Functions may only reference local variables which are defined in the local
environment prior to function creation. Mutually recursive functions local can
be defined by putting definitions in a single with or let expression.

*** let
Syntax:
#+begin_src
let-expr ::= "(" "let" let-pair+ ")"
let-pair ::= identifier expr
#+end_src

Extends the current local environment. For each let-pair initially binds the
provided identifier to null. Then, in the order provided, each expression is
evaluated and the binding is updated to the resultant value.

The initial null-binding allows definition of recursive and even mutually
recursive functions. Care must be taken because this null binding will shadow
existing variables with the same name.

Returns null.

*** letfn
*** or
Syntax:
#+begin_src
or-expr ::= "(" "or" expr* ")"
#+end_src

Evaluates provided expressions one at a time until a logically true value is
obtained. Then returns ~true~. If the end of the list is reached, returns ~false~.

*** quasiquote
Syntax:
#+begin_src
quasiquote-expr ::= "`" form
                | "(" "quasiquote" form ")"
#+end_src

First, creates a fn object corresponding to form just like quote. Before
returning the form, the following transformation is done:
- The form is walked like a tree.
- When an unquote-expr is encountered, instead of descending into it, evaluate
  its argument and insert the result into the tree at that point.
- When an unquote-splicing form is encountered, instead of descending into it,
  evaluate its argument. If the result is not a list or if this is root of the
  tree, raise an error. Otherwise, splice the elements of the list inline into
  the tree at this point.
- Along the way, we keep track of all symbols whose names begin with a hash
  character "#". For each unique hash symbol, a single gensym is created, and
  the hash symbols are replaced by the gensyms in the final expansion. For
  example, see the following code snippet:

#+begin_src
`(#sym1 #sym2 #sym2) ; has the same value as
(with (sym1 (gensym)
       sym2 (gensym))
 [sym1 sym2 sym2])
#+end_src
*** quote
Syntax:
#+begin_src
quote-expr ::= "'" form
           | "(" "quote" form ")"
#+end_src

Returns the syntactic form as an fn object (a tree of atoms and lists).

*** unquote
Syntax:
#+begin_src
unquote-expr ::= "," expr
             | "(" "unquote" expr ")"
#+end_src
Emits an error unless encountered within a quasiquote form.

*** unquote-splicing
Syntax:
#+begin_src
unquote-splicing-expr ::= ",@" expr | "(" "unquote-splicing" expr ")"
#+end_src
Emits an error unless encountered within a quasiquote form.

*** TODO set!
Syntax:
#+begin_src
set!-form ::= "(" "set!" place expr ")"
place ::= identifier 
      | dot-expr
      | get-form
get-form ::= "(" "get" expr+ ")"
#+end_src

*** with
Syntax:
#+begin_src
with-expr ::= "(" with-bindings expr+ ")"
with-bindings ::= "(" (id expr)* ")"
#+end_src

Behaves like ~let~, but rather than operating on the enclosing lexical
environment, instead creates a new child environment and adds bindings to that,
then evaluates the provided expressions in the newly created environment.

Note that this is how ~let~ works in most LISP-like languages.


** Function Calls

Syntax:
#+begin_src
function-call ::= "(" func argument-list ")"
#+end_src
where ~func~ may be any expression other than a reserved symbol.

First, the function and then all the arguments are evaluated from left to right.
(The operator here could also be a table, see [[Calling Tables as Functions]]).

Arguments are bound to parameters as follows:

Positional arguments are bound to the function's parameters in the order
provided. If there are more positional arguments than parameters, a list of the
extras are bound to the variadic list parameter if one exists. If not, an error
is generated.

After this, keyword arguments are bound to parameters by name. If two keyword
arguments have the same name, an error is raised. If the name isn't one of the
function's parameters, or if it names a parameter already provided by a
positional argument, it is added to the variadic table parameter if one exists.
If not, an error is raised.

If any parameters without default values remain unbound, an error is raised.

Then, the function is called. Foreign functions have behavior determined by the
external code they call. Ordinary functions work by switching back to the
lexical environment in which they were created, binding parameters as local
variables, and executing the function body.


** Calling Tables as Functions

A table may used as functions by setting its ~'__on-call__~ entry to an
appropriate function. When the table is called, this function is invoked with
the table itself as the first argument, followed by the arguments provided in
the initial call. E.g. ~(tab x y)~ is equivalent to ~(tab.__on-call__ tab x y)~.

When defining the function for ~__on-call__~, it is conventional to name the
first argument ~this~.


** Macro Calls
Syntax:
#+begin_src
macro-call ::= "(" macro-name form* ")"
macro-name ::= identifier | dot-expr
#+end_src

The expressions for macro arguments aren't evaluated, but are converted to data
and passed to the macro function as arguments. The resultant value is treated as
code and evaluated.

In order to prevent ambiguity, macros do not recognize keyword arguments. A
keyword will be passed to the macro as a positional argument containing the
keyword symbol.


* TODO Built-in Functions

Primitives:
- apply
- get
- gensym

- Bool
- List
- String
- Table

- bool?
- function?
- list?
- number?
- namespace?
- null?
- string?
- symbol?
- table?

Lists:
- empty?
- cons

Sequences (lists & strings):

Tables:
- has-key?
- table-keys

Strings and Lists (other sequences, some day):

(Note: a user type can implement any or all of these functions by adding methods
for them. Sorry, that isn't documented yet).

All of these are non-destructive.

- concat (& seqs)
- reverse (seq)

- insert (elt n seq)
- append (elt seq)
- prepend (elt seq)
- sort (seq (ascending true))
- sort-by (fun seq (ascending true))

- head (seq)
- tail (seq)
- nth (n seq)

- take (test seq)
- drop (test seq)
- take-while (test seq)
- drop-while (test seq)
- split-at (n seq)
- split-when (test seq)

- group (n seq)
- group-by (key seq)
- subseq (start end seq)

- dedup (seq) [remove duplicates]
- replace (n elt seq)

- empty? (seq)
- contains? (seq)

- length< (seq n) [compare lengths w/o nec. computing the thing]
- length> (seq n)
- length<= (seq n)
- length>= (seq n)

- map (fun seq0 & seqs)
- fold (fun init seq0 & seqs)
- filter (test seq)
- every? (test seq)
- any? (test seq)


* Future Functionality

Features I would like to add:
- integer datatypes (including fixnum)
- docstrings for variables, functions, and macros
- vector/array native datatype
- (maybe) bytes data structure
- (maybe) dynamic variables
- foreign function interface
- built-in packages for I/O (including sockets/IPC), subroutine management, and
  threading

